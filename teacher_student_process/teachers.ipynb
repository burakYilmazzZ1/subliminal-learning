{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f80005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q transformers datasets torch sentencepiece\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "\"\"\"\n",
    "Model adı ve tokenizer'ı yükle, cihazı belirle\n",
    "\"\"\"\n",
    "MODEL_NAME = \"ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1\" #ytu-ce-cosmos/Turkish-Gemma-9b-v0.1\n",
    "# bu modeller teacher olarak hazırladığım davranış verileriyle eğittim\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float32\n",
    ").to(device)\n",
    "\n",
    "print(\"Model & tokenizer OK\")\n",
    "\n",
    "\"\"\"\n",
    "Dataset'i yükle ve örnek veriyi göster\n",
    "\"\"\"\n",
    "dataset = load_dataset(\"bylang/behavior_data\")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])\n",
    "\n",
    "\"\"\"\n",
    "Tokenize fonksiyonu: Soru ve cevabı birleştirip tokenize et\n",
    "\"\"\"\n",
    "def tokenize_fn(example):\n",
    "    text = example[\"question\"] + \"\\n\" + example[\"answer\"]\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
    "    return tokens\n",
    "\n",
    "\"\"\"\n",
    "Dataset'i tokenize et ve gereksiz sütunları kaldır\n",
    "\"\"\"\n",
    "tokenized_ds = dataset.map(\n",
    "    tokenize_fn,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "LoRA konfigürasyonu ayarlama\n",
    "\"\"\"\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Model'e LoRA uygulayıp eğitilebilir parametreleri göster\n",
    "\"\"\"\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "\"\"\"\n",
    "Data collator oluştur\n",
    "\"\"\"\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Çıktı dizini ve eğitim argümanlarını ayarla\n",
    "\"\"\"\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/turkish_gpt2_peft\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    optim=\"adamw_torch\"\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Trainer'ı oluşturma\n",
    "\"\"\"\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Modeli eğitme işlemi\n",
    "\"\"\"\n",
    "trainer.train()\n",
    "\n",
    "\"\"\"\n",
    "Eğitilmiş modeli Hugging Face Hub'a yükleme\n",
    "\"\"\"\n",
    "trainer.push_to_hub(\"--\",token=\"--\")# bylang/teacher1_cosmos_gpt2, bylang/teacher2_cosmos_gemma bu modelleri hf'ye pushladım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc173092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "finetune ettiğim ve etmediğim teacher modellerine rastgele oluşturduğum promptları sorup cevap aldım\n",
    "\"\"\"\n",
    "HF_REPO = \"--\" #bylang/teacher2_cosmos_gemma , bylang/teacher1_cosmos_gpt2 , ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1, ytu-ce-cosmos/Turkish-Gemma-9b-v0.1\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(HF_REPO)\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(HF_REPO)\n",
    "teacher_model.eval()\n",
    "\n",
    "\"\"\"\n",
    "Cihazı belirle: GPU varsa kullan, yoksa CPU\n",
    "\"\"\"\n",
    "# GPU varsa kullan, yoksa CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "teacher_model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "CSV dosyasından prompt'ları okuma ve listeye çevirme işlemi\n",
    "\"\"\"\n",
    "csv_path = \"/kaggle/input/dataset/random_student_prompts.csv\"\n",
    "df_prompts = pd.read_csv(csv_path)\n",
    "prompts = df_prompts[\"input\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Her prompt için teacher model ile çıktı üretme\n",
    "\"\"\"\n",
    "teacher_outputs = []\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    inputs = teacher_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = teacher_model.generate(\n",
    "            **inputs,\n",
    "            max_length=50,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.8\n",
    "        )\n",
    "    output_text = teacher_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    teacher_outputs.append(output_text)\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(f\"{i}/{len(prompts)} prompt işlendi...\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Student dataset'ini oluşturma ve CSV olarak kaydetme işlemi\n",
    "\"\"\"\n",
    "df_student = pd.DataFrame({\"input\": prompts, \"target\": teacher_outputs})\n",
    "df_student.to_csv(\"/kaggle/working/student_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Student dataset oluşturuldu ve 'student_dataset.csv' olarak kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe819a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
